{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# U.T.4 Aprendizaje supervisado (II).\n",
    "# Introducción a los problemas de regresión\n",
    "**Qué es la regresión**\n",
    "\n",
    "La regresión intenta predecir el valor de una variable de salida, a partir de las variables de entrada,\n",
    "dentro de una escala continua en vez de un conjunto de etiquetas (clasificación)\n",
    "\n",
    "\n",
    "## Regresión lineal\n",
    "Intenta utilizar elemento geométrico recto (línea, plano, hiperplano) para intentar las predicciones.\n",
    "La RL se puede dividir en simple o múltiple dependiendo del número de variables de entrada.\n",
    "Generalmente no es necesario que las variables estén distribuidas según la normal.\n",
    "\n",
    "Los modelos de regresión lineal son muy dependientes (LinearRegression) de los valores extremos.\n",
    "\n",
    "la clase RANSACRegressor utiliza un algoritmo de detección de extremos bastante potente, pero no debemos olvidar que\n",
    "habrá que estudiar en profundidad el problema y los extremos para determinar qué hacer con ellos.\n",
    "El parámetro residual_threshold de la clase RANSACRegressor, es dependiente del problema que se esté tratando y\n",
    "no se puede determinar más que con el mecanismo de prueba y error.\n",
    "\n",
    "Para medir el rendimiento podemos usar la métrica MSE.\n",
    "\n",
    "Al igual que en el modelo de clasificación podemos usar las regularizaciones L2 (Lasso), L1(Ridge) o Elastic para\n",
    "hacer la regresión"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slope: 9.102\n",
      "Intercept: -34.671\n",
      "MSE train: 42.179, test: 46.911\n",
      "R^2 train: 0.502, test: 0.437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, RANSACRegressor\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Estimación de modelo\n",
    "df = pd.read_csv('housing.data.txt', header=None, sep='\\s+')\n",
    "df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "X = df[['RM']].values\n",
    "y = df['MEDV'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "\n",
    "slr = LinearRegression()\n",
    "slr.fit(X, y)\n",
    "y_pred = slr.predict(X)\n",
    "print('Slope: %.3f' % slr.coef_[0])\n",
    "print('Intercept: %.3f' % slr.intercept_)\n",
    "\n",
    "# Medimos Regresión Lineal\n",
    "y_train_pred = slr.predict(X_train)\n",
    "y_test_pred = slr.predict(X_test)\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "    mean_squared_error(y_train, y_train_pred),\n",
    "    mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "    r2_score(y_train, y_train_pred),\n",
    "    r2_score(y_test, y_test_pred)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regresión polinomial\n",
    "Intenta utilizar un ecuación polinomial para intentar las predicciones.\n",
    "La aproximación es la misma que la llevada en la clasificación con los mismos problemas de sobre ajuste,\n",
    "por lo que la elección del grado del polinomio debe hacerse de forma muy cuidadosa."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(0.5484256373971057, 0.561225722635539)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "regr = LinearRegression()\n",
    "\n",
    "quadratic = PolynomialFeatures(degree=2)\n",
    "cubic = PolynomialFeatures(degree=3)\n",
    "X_quad = quadratic.fit_transform(X)\n",
    "X_cubic = cubic.fit_transform(X)\n",
    "\n",
    "X_fit = np.arange(X.min(), X.max(), 1)[:, np.newaxis]\n",
    "\n",
    "regr = regr.fit(X_quad, y)\n",
    "y_quad_fit = regr.predict(quadratic.fit_transform(X_fit))\n",
    "quadratic_r2 = r2_score(y, regr.predict(X_quad))\n",
    "\n",
    "regr = regr.fit(X_cubic, y)\n",
    "y_cubic_fit = regr.predict(cubic.fit_transform(X_fit))\n",
    "cubic_r2 = r2_score(y, regr.predict(X_cubic))\n",
    "\n",
    "quadratic_r2, cubic_r2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regresión usando bosques aleatorios\n",
    "El modelo usará la misma técnica que se vio en la clasificación, ajustando un conjunto de árboles de decisión\n",
    "independientes. La ventaja de este método es que no necesita ningún tipo de transformación de las características."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 6.325, test: 50.921\n",
      "R^2 train: 0.921, test: 0.436\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "df = pd.read_csv('housing.data.txt', header=None, sep='\\s+')\n",
    "df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS',\n",
    "              'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
    "              'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "forest = RandomForestRegressor(n_estimators=1000, criterion='mse', random_state=1, n_jobs=-1)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "y_train_pred = forest.predict(X_train)\n",
    "y_test_pred = forest.predict(X_test)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "    mean_squared_error(y_train, y_train_pred),\n",
    "    mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "    r2_score(y_train, y_train_pred),\n",
    "    r2_score(y_test, y_test_pred)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Regresión usando SVM\n",
    "También se pueden usar las máquinas de soporte vector para problemas de regresión. Con este algoritmo es muy importante\n",
    "escalar las características."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE train: 0.150, test: 0.197\n",
      "R^2 train: 0.842, test: 0.816\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df = pd.read_csv('housing.data.txt', header=None, sep='\\s+')\n",
    "df.columns = ['CRIM', 'ZN', 'INDUS', 'CHAS',\n",
    "              'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
    "              'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "X = df.iloc[:, :-1].values\n",
    "y = np.array(df['MEDV'].values).reshape(-1, 1)\n",
    "\n",
    "sc_X = StandardScaler()\n",
    "sc_y = StandardScaler()\n",
    "X = sc_X.fit_transform(X)\n",
    "y = sc_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "svm = SVR(kernel='rbf')\n",
    "svm.fit(X_train, y_train.ravel())\n",
    "y_train_pred = svm.predict(X_train)\n",
    "y_test_pred = svm.predict(X_test)\n",
    "\n",
    "print('MSE train: %.3f, test: %.3f' % (\n",
    "    mean_squared_error(y_train, y_train_pred),\n",
    "    mean_squared_error(y_test, y_test_pred)))\n",
    "print('R^2 train: %.3f, test: %.3f' % (\n",
    "    r2_score(y_train, y_train_pred),\n",
    "    r2_score(y_test, y_test_pred)))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}