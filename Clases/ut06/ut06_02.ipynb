{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# U.T.6 Redes Neuronales.\n",
    "## Tensorflow\n",
    "### Introducción\n",
    "Tensorflow es una librería escalable para la programación de machine Learning desarrollada por Google y liberada en 2015.\n",
    "Con la versión 2 de la librería se está convirtiendo en el estándar para el ML al simplificar mucho su uso\n",
    "\n",
    "La principal ventaja es que es eficiente sobre cualquier tipo de procesador, incluso con estructuras distribuidas.\n",
    "Esta librería hace un uso eficiente de las GPU de nuestra máquina si ésta tiene núcleos CUDA o TPUs así como clusters o\n",
    "cualquier estructura hardware de computación\n",
    "\n",
    "Es imprescindible tener una GPU para ML si queremos realizar algoritmos decentes. Una estimación: en una CPU normal\n",
    "actual puede tardar una semana en compilarse una modelo, con una RTX 2080Ti tardará unas horas.\n",
    "Otra opción es usar los servicios distribuidos para ML Learning de Google, Keras, Microsoft, etc…\n",
    "\n",
    "### Instalación y configuración\n",
    "pip install tensorflow\n",
    "\n",
    "https://docs.nvidia.com/cuda/index.html#installation-guides\n",
    "\n",
    "### Estructura\n",
    "![](img/ut06_24.png)\n",
    "\n",
    "### Operaciones básicas"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#  Inicio\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)  # 2.3.1\n",
    "a = np.array([1, 2, 3], dtype=np.int32)   # Definimos un array numpy\n",
    "b = [4, 5, 6]  # Definimos una lista\n",
    "#  Creamos los tensores correspondientes\n",
    "t_a = tf.convert_to_tensor(a)\n",
    "t_b = tf.convert_to_tensor(b)\n",
    "print(t_a)  # tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
    "print(t_b)  # tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n",
    "\n",
    "#  Comprobamos si son tensores dos variables\n",
    "print(tf.is_tensor(a), tf.is_tensor(t_a))  # False True\n",
    "\n",
    "#  Creamos un tensor bidimensional relleno de unos\n",
    "t_ones = tf.ones((2, 3))\n",
    "print(t_ones.shape)  # (2, 3)\n",
    "\n",
    "# Accedemos al array de numpy del tensor\n",
    "print(t_ones.numpy())\n",
    "\n",
    "#  Creamos un tensor constante, con tres valores de rango uno.\n",
    "const_tensor = tf.constant([1.2, 5, np.pi], dtype=tf.float32)\n",
    "print(const_tensor)\n",
    "\n",
    "# Conversiones entre NumpPy\n",
    "print(type(t_ones.numpy()))  # <class 'numpy.ndarray'>\n",
    "print(type(np.array(t_ones)))  # <class 'numpy.ndarray'>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Acceso a los datos indexados"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(t_ones[:, 1:])\n",
    "print(t_ones[..., 1, tf.newaxis])\n",
    "print(t_a + 10)  # tf.Tensor([11 12 13], shape=(3,), dtype=int32)\n",
    "print(tf.square(t_a))  # tf.Tensor([1 4 9], shape=(3,), dtype=int32)\n",
    "print(t_ones @ tf.transpose(t_ones))  # @ equivalente a tf.matmul()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manejo del tipo de los datos y su dimensión"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_a_new = tf.cast(t_a, tf.int64)  # Cambiamos el tipo a int64 del tensor t_a\n",
    "print(t_a_new.dtype)  # <dtype: 'int64'>\n",
    "t = tf.random.uniform(shape=(3, 5))  # los elementos en una matriz de 3 por 5\n",
    "t_tr = tf.transpose(t)  # Hacemos la transpuesta\n",
    "print(t.shape, ' --> ', t_tr.shape)  # (3, 5)  -->  (5, 3)\n",
    "t = tf.zeros((30,))  # Creamos un tensor de rango 1 con 30 ceros\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))  # un tensor de rango 2 de 5 por 6\n",
    "print(t_reshape.shape)  # (5, 6)\n",
    "t = tf.zeros((3, 2, 1, 4, 1))  # Tensor 5 dimensiones, cada uno con 3,2,1,4,1 ceros\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Eliminamos la tercera y la quinta dimensión, se empieza en cero"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "t_sqz = tf.squeeze(t, axis=(2, 4))\n",
    "print(t.shape, ' --> ', t_sqz.shape)  # (3, 2, 1, 4, 1)  -->  (3, 2, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Operaciones matemáticas"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "t1 = tf.random.uniform(shape=(5, 2), minval=-1.0, maxval=1.0)\n",
    "t2 = tf.random.normal(shape=(5, 2),  mean=0.0, stddev=1.0)\n",
    "print(t1, t2)\n",
    "t3 = tf.multiply(t1, t2).numpy()\n",
    "t4_a = tf.math.reduce_mean(t1, axis=0)  # por columnas axis=0\n",
    "t4_b = tf.math.reduce_mean(t1, axis=1)  # por filas axis=1\n",
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True)\n",
    "print(t5.numpy())\n",
    "t6 = tf.linalg.matmul(t1, t2, transpose_a=True)\n",
    "print(t6.numpy())\n",
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\n",
    "print(norm_t1)\n",
    "print(np.sqrt(np.sum(np.square(t1), axis=1)))  # Por filas axis=1\n",
    "print(np.sqrt(np.sum(np.square(t1), axis=0)))  # Por columnas axis=0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Variales y constantes\n",
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v.assign(2 * v)\n",
    "print(v)  # => [[2., 4., 6.], [8., 10., 12.]]\n",
    "v[0, 1].assign(42)\n",
    "print(v)  # => [[2., 42., 6.], [8., 10., 12.]]\n",
    "v[:, 2].assign([0., 1.])\n",
    "print(v)  # => [[2., 42., 0.], [8., 10., 1.]]\n",
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])\n",
    "print(v)  # => [[100., 42., 0.], [8., 10., 200.]]\n",
    "\n",
    "a = tf.Variable(initial_value=3.14, name='var_a')\n",
    "b = tf.Variable(initial_value=[1, 2, 3], name='var_b')\n",
    "c = tf.Variable(initial_value=[True, False], dtype=tf.bool)\n",
    "d = tf.Variable(initial_value=['abc'], dtype=tf.string)\n",
    "\n",
    "w = tf.Variable([1, 2, 3], trainable=False)\n",
    "print(w.assign([3, 1, 4], read_value=True))\n",
    "w.assign_add([2, -1, 2], read_value=False)\n",
    "\n",
    "init = tf.keras.initializers.GlorotNormal()\n",
    "w = tf.Variable(init(shape=(2, 3)))\n",
    "w = tf.Variable(tf.random.uniform((3, 3)))\n",
    "\n",
    "ct = tf.constant([1, 2, 3])\n",
    "print(ct)  # tf.Tensor([1 2 3], shape=(3,), dtype=int32)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Divisiones e uniones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((6,))\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, 3)   # Dividimos en bloques de tres\n",
    "for item in t_splits:\n",
    "    print(item.numpy())\n",
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((5,))\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, num_or_size_splits=[3, 2])\n",
    "for item in t_splits:\n",
    "    print(item.numpy())\n",
    "A = tf.ones((3,))\n",
    "B = tf.zeros((2,))\n",
    "C = tf.concat([A, B], axis=0)\n",
    "print(C.numpy())  # [1. 1. 1. 0. 0.]\n",
    "A = tf.ones((3,))\n",
    "B = tf.zeros((3,))\n",
    "S = tf.stack([A, B], axis=0)   # Por columnas axis=0\n",
    "print(S.numpy())\n",
    "S = tf.stack([A, B], axis=1)  # Por filas axis=1\n",
    "print(S.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Funciones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_z(a, b, c):\n",
    "    r1 = tf.subtract(a, b)\n",
    "    r2 = tf.multiply(2, r1)\n",
    "    z = tf.add(r2, c)\n",
    "    return z\n",
    "\n",
    "tf.print('Scalar Inputs:', compute_z(1, 2, 3))\n",
    "tf.print('Rank 1 Inputs:', compute_z([1], [2], [3]))\n",
    "tf.print('Rank 2 Inputs:', compute_z([[1]], [[2]], [[3]]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normas al crear funciones\n",
    "- Un gráfico solo puede tener llamadas a otras funciones de TensorFlow.\n",
    "- Se pueden llamar a otras funciones Python si solo tienen código TensorFlow.\n",
    "- Si se crean variables deben ser las primeras líneas, o mejor hacerlas fuera de la función.\n",
    "- Se debe proporcionar el código fuente de forma externa para que funcione, no se puede dar código Python compilado.\n",
    "- Los bucles for de Python solo se capturarán si son sobre Dataset o Tensores (usar tf.range en vez de range).\n",
    "- Usar versiones vectorizadas de las operaciones mejores que los bucles al mejorar la eficiencia.\n",
    "\n",
    "### Uso de hardware avanzado\n",
    "En caso que tengamos una tarjeta gráfica con una GPU habilitada para ML podremos hacer uso de todas las aceleraciones\n",
    "existentes, pero para ello deberá ser compatible con NVIDIA y tener instalado el Toolkit CUDA, la librería NVIDIA\n",
    "cuDNN\n",
    "\n",
    "https://docs.nvidia.com/cuda/index.html#installation-guides\n",
    "\n",
    "Para saber a qué dispositivos están asignados sus operaciones y tensores, hay que colocar\n",
    "tf.debugging.set_log_device_placement(True) como la primera declaración de su programa. Al habilitar el\n",
    "registro de ubicación de dispositivos, se imprimen las asignaciones u operaciones de Tensor.\n",
    "\n",
    "https://www.tensorflow.org/guide/gpu\n",
    "\n",
    "### Uso de TPUs\n",
    "Las TPU son unidades hardware desarrolladas específicamente para el entrenamiento de redes neuronales por Google.\n",
    "El soporte experimental para Cloud TPU actualmente está disponible para Keras y Google Colab.\n",
    "\n",
    "https://www.tensorflow.org/guide/tpu\n",
    "\n",
    "### Uso de la nube\n",
    "TensorFlow Cloud es un paquete de Python que proporciona API para una transición perfecta de la depuración local al\n",
    "entrenamiento distribuido en Google Cloud. Simplifica el proceso de entrenamiento de modelos de TensorFlow en la nube\n",
    "en una única llamada, que requiere una configuración mínima y sin cambios en su modelo. TensorFlow Cloud maneja tareas\n",
    "específicas de la nube, como crear instancias de VM y estrategias de distribución para sus modelos automáticamente.\n",
    "\n",
    "https://www.tensorflow.org/guide/keras/training_keras_models_on_cloud\n",
    "\n",
    "https://github.com/tensorflow/cloud/blob/master/src/python/tensorflow_cloud/core/tests/examples/dogs_classification.ipynb\n",
    "\n",
    "https://www.tensorflow.org/guide/distributed_training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}