{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# U.T.6 Redes Neuronales.\n",
    "## Ajuste de la red\n",
    "### Introducción\n",
    "Las redes neuronales que pueden ser sustituidas por algoritmos de regresión o clasificación no suelen\n",
    "ser muy profundas (muchas capas) por lo que no presentan graves problemas.\n",
    "\n",
    "Es cuando avanzamos en el entrenamiento de redes más grandes cuando aparecen ciertos problemas:\n",
    "- Desajustes en los crecimientos de los gradientes\n",
    "- No tengamos acceso a suficientes datos\n",
    "- El entrenamiento puede que nos lleve mucho tiempo\n",
    "- Se puede sobreajustar a los datos\n",
    "\n",
    "Para prevenir que un modelo aprenda patrones irrelevantes, la mejor aproximación es conseguir más\n",
    "datos para entrenarlo. Si no es posible, reduciendo la capacidad de la red podremos forzar a que se\n",
    "centre en los patrones relevantes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "Reducir el tamaño de la red (reducir capas o neuronas)\n",
    "El verdadero problema en las redes neuronales es la generalización\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(4, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(4, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid’))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(10000,)))\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](img/ut06_15.png)\n",
    "### Desajustes en los gradientes.\n",
    "El algoritmo de backpropagacion va desde la capa de salida y va subiendo por la estructura hasta la capa de entrada,\n",
    "aplicando el reajuste de pesos de abajo a arriba\n",
    "\n",
    "Problemas\n",
    "- El gradiente que se va calculando al aplicarlo en este orden hace que las capas más cercanas a la entrada queden\n",
    "prácticamente invariadas con lo que la solución nunca converge (desvanecimiento del gradiente)\n",
    "- Los cambios se hace cada vez mayor, siendo enorme en las capas más cercanas a la entrada (estallido del gradiente)\n",
    "haciendo que el problema tampoco converja\n",
    "- En las NN de gran tamaño cada capa aprenderá a ritmos muy diferentes\n",
    "\n",
    "#### Solución 1: Inicialización Glorot y He\n",
    "inicializar los pesos de forma aleatoria. Keras usa la inicialización Glorot\n",
    "\n",
    "keras.layers.Dense(10, activation=\"relu\",  kernel_initializer=\"he_normal\")\n",
    "keras.layers.Dense(10, activation=\"relu\", kernel_initializer=\"lecun_normal\")\n",
    "\n",
    "\n",
    "Restricciones\n",
    "\tInicialización\tFunción de activación\n",
    "\n",
    "\tGlorot\t\tNone, tanh, logistic, softmax\n",
    "\n",
    "\tHe\t\t    ReLU and variants\n",
    "\n",
    "\tLeCun\t\tSELU\n",
    "\n",
    "#### Solución 2: Funciones que no saturan\n",
    "- RELU. Buena aproximación pero algunas neuronas no aportarán nada\n",
    "- Leaky RELU. Se puede controlar el ajuste a través del parámetro alfa. Valores típicos son 0.01, 0.1 o 0.2\n",
    "- ELU. Mejora los tiempos de aprendizaje, tiene un parámetro alfa que se suele ajustar a 1. Tiene un gran coste\n",
    "computacional\n",
    "- SELU. Variante escalada de SELU. Se autonormaliza. Deben darse las siguientes condiciones: Entradas estandarizadas,\n",
    "la capa oculta inicializada con LeCum, la arquitectura debe ser secuencial y todas las capas densas.\n",
    "\n",
    "**SELU > ELU > Leake RELU >> RELU > Tang > Logistic**\n",
    "\n",
    "#### Solución 3: Normalización Batch\n",
    "Se basa en centrar en cero las entradas y normalizar, escalarlas y desplazarlas utilizando nuevos parámetros por\n",
    "cada capa.\n",
    "\n",
    "Si se añade como primera capa después de la entrada o del aplanado (Flatter) conseguiremos que se normalicen\n",
    "las entradas y no será necesario que lo hagamos nosotros antes.\n",
    "\n",
    "Se puede hacer justo antes de cada capa oculta (aunque hay estudios que defienden que se haga después).\n",
    "\n",
    "Puede mejorar hasta grados del 2% solo añadiendo las capas sin afinar nada.\n",
    "\n",
    "La desventaja es que añade complejidad al modelo, aumentando el tiempo de procesamiento, pero a cambio disminuye el\n",
    "número de épocas para converger.\n",
    "\n",
    "**Parámetros**\n",
    "momentum. Este valor suele estar muy cercano a uno 0.9 y se añadirán más nuevos al valor cuanto más pequeño es el\n",
    "tamaño del mini-batch\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "\tkeras.layers.Flatten(input_shape=[28, 28]),\n",
    "\tkeras.layers.BatchNormalization(),\n",
    "\tkeras.layers.Dense(300, activation=\"elu\",\n",
    "\t\tkernel_initializer=\"he_normal\"),\n",
    "\tkeras.layers.BatchNormalization(),\n",
    "\tkeras.layers.Dense(100, activation=\"elu\",\n",
    "\t\tkernel_initializer=\"he_normal\"),\n",
    "\tkeras.layers.BatchNormalization(),\n",
    "\tkeras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "\n",
    "Evita el reshape antes de la entrada de la red hecho hasta ahora\n",
    "\n",
    "#### Solución 4: Recorte del gradiente\n",
    "Se basa en recortar el tamaño del gradiente durante la backpropagación, evitando el problema de la explosión del\n",
    "gradiente. Con esta técnica se limita el valor máximo que puede tener el cambio\n",
    "\n",
    "El problema es que al realizar el corte se pueden presentar otros problemas, como que no se preserve la orientación\n",
    "o se elimine el valor de una de las direcciones. Así un vector vale (0.9,100) y se aplica el recorte quedará en\n",
    "(0.9,1) cambiando la dirección del vector. Del mismo modo si e hace un corte normalizado el resultado será (0.008, 1)\n",
    " con lo que la primera componente prácticamente se anula.\n",
    "\n",
    "optimizer = keras.optimizers.SGD(clipvalue=1.0)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Uso de redes entrenadas\n",
    "No es una buena idea entrenar una red grande si existe otra que haga un trabajo similar. El entrenamiento puede ser\n",
    "una tarea muy costosa y si podemos reutilizar partes de otros modelos ya entrenados y validados se adelantará mucho,\n",
    "esta técnica se llama transferencia del aprendizaje\n",
    "\n",
    "La idea principal es transferir las capas más cercanas a la entrada a nuestro modelo manteniendo los pesos. A\n",
    "continuación, añadimos las capas superiores que creamos convenientes y entrenamos el modelo con nuestros datos,\n",
    "forzando al cambio a las capas que hemos añadido\n",
    "\n",
    "![](img/ut06_16.png)\n",
    "\n",
    "Este procedimiento es muy válido y se utiliza mucho, lo único que deberemos tener algunas consideraciones:\n",
    "- Si los modelos no tienen las mismas características de entrada, habrá que realizar un proceso de adaptación de\n",
    "nuestros ejemplos al nuevo número de entradas.\n",
    "- Generalmente la capa de salida debe ser remplazada para que se adecue al problema que estamos resolviendo.\n",
    "\n",
    "Si no se ajusta, iremos liberando capas fijas de arriba a abajo de pocas en pocas y entrenando de nuevo para que\n",
    "mejore el ajuste, cuantos más ejemplos de entrada tengamos más capas podremos liberar. No nos podemos olvidar ajustar\n",
    "la tasa de aprendizaje correctamente, generalmente a un valor bajo.\n",
    "\n",
    "Tenemos que tener especial cuidado con los estudios que se hacen en DeepLearning, en los que se muestran algoritmos\n",
    "que funcionan muy bien con ciertos parámetros, o ciertos ajustes que son los que hay que usar. Estos estudios muestran\n",
    "los resultados, pero muy pocas veces dicen los intentos que se han tenido que hacer hasta encontrar esos resultados,\n",
    "por lo que un valor presentado parece que es el mejor pero lo que pasa es que los fallos no se muestran, por lo que no\n",
    "se puede evaluar correctamente el funcionamiento.\n",
    "\n",
    "No hay que obviar que esta técnica no funciona bien con pequeñas redes densas, mejora mucho con redes convolucionales profundas\n",
    "\n",
    "Se verá más adelante con redes convolucionales"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Optimizadores rápidos\n",
    "Entrenar DNN puede ser computacionalmente muy costoso y llevar una gran cantidad de tiempo. Para acelerar el proceso\n",
    "se utilizan algoritmos de optimización rápidos.\n",
    "\n",
    "#### Optimización del momento\n",
    "Inicio lento de la optimización y en cada iteración aplicar más cantidad, el momento se toma como un valor de\n",
    "aceleración a la velocidad actual de aprendizaje, en vez de la velocidad en sí misma. El valor general de este\n",
    "optimizador es de 0.9.\n",
    "\n",
    "La pregunta es para qué esta optimización. La respuesta es sencilla, las funciones pueden tener mínimos locales en\n",
    "los que queden estancados los algoritmos, y esta “aceleración” extrá permitirá saltarlos\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "#### NAG (Nesterov accelerated Gradient).\n",
    "Es una pequeña variación del anterior que hace que sea más rápido que el GD o SGD.\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "\n",
    "#### AdaGrad\n",
    "Escala la dirección del vector gradiente a en la dirección más empinada. Funciona muy bien para problemas cuadráticos,\n",
    "pero se para muy pronto para NN. No se debe utilizar en problemas de Deep Learning ya que presenta el riesgo que pare\n",
    "demasiado pronto en un mínimo local en vez del global.\n",
    "\n",
    "#### RMSProp.\n",
    "Este algoritmo mejora los problemas del anterior introduciendo un nuevo hiperparámentro beta que generalmente se\n",
    "establece a 0.9.\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "\n",
    "#### ADAM.\n",
    "Combina las ideas de momento y RMSPROP en un único algoritmo, por lo que incorpora dos nuevos hiperparámetros pero\n",
    "generalmente los valores mostrados dan buenos resultados. (NADAM. Es similar a ADAM con una nueva optimización, que\n",
    "generalmente hace que converja algo más rápido)\n",
    "\n",
    "\n",
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "#### Uso\n",
    "Una vez definido y establecido el optimizador se pasará como parámetro a la función compile.\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "\n",
    "![](img/ut06_17.png)\n",
    "\n",
    "### Gestión de la tasa de aprendizaje\n",
    "#### Introducción\n",
    "Hasta ahora la tasa de aprendizaje permanece constante entre las diferentes épocas. Vamos a explorar la idea de que\n",
    "esta varía dependiendo del momento de aprendizaje\n",
    "\n",
    "#### La primera idea\n",
    "Podemos utilizar para encontrar la tasa adecuada de aprendizaje es entrenar nuestro modelo con solo unos cientos de\n",
    "épocas, incrementando de forma exponencial en cada una de ellas el valor de la tasa de aprendizaje. Una vez realizado\n",
    "e muestra la curva de aprendizaje utilizando como tasa de aprendizaje un poco menor al punto en el que la curva vuelve\n",
    "a crecer. Con esta tasa entrenar de nuevo el modelo completamente.\n",
    "\n",
    "![](img/ut06_18.png)\n",
    "\n",
    "#### La segunda idea\n",
    "Empezar con una tasa de aprendizaje elevada y la vamos reduciendo en cada época de forma progresiva\n",
    "\n",
    "##### Power scheduling.\n",
    "Primero avanza muy rápido y después cada vez más lento, tiene un par de hipeparámetros a ajustar.\n",
    "\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay=1e-4)\n",
    "\n",
    "##### Exponential scheduling.\n",
    "El descenso se hace de forma exponencial en un factor de diez cada vez.\n",
    "\n",
    "def exponential_decay_fn(epoch):\n",
    "\treturn 0.01 * 0.1**(epoch / 20)\n",
    "\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(X_train_scaled, y_train, [...], callbacks=[lr_scheduler])\n",
    "\n",
    "##### Piecewise constant scheduling.\n",
    "Divide el entrenamiento en tres periodos en función de las épocas y utiliza para cada una de ellas una tasa de\n",
    "aprendizaje fija, pero diferente entre ellas.\n",
    "\n",
    "\n",
    "def piecewise_constant_fn(epoch):\n",
    "\tif epoch < 5:\n",
    "\t\treturn 0.01\n",
    "\telif epoch < 15:\n",
    "\t\treturn 0.005\n",
    "\telse:\n",
    "\t\treturn 0.001\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(piecewise_constant_fn)\n",
    "history = model.fit(X_train_scaled, y_train, [...],  callbacks=[lr_scheduler])\n",
    "\n",
    "##### Performance scheduling.\n",
    "Mide el error de validación cada N pasos y reduce la tasa de aprendizaje en un factor (hiperparámetro) cuando el error\n",
    "deja cambiar.\n",
    "\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "\n",
    "##### One cicle scheduling.\n",
    "Divide el aprendizaje en dos periodos, en el primero la tasa de aprendizaje se incrementará y en el segundo descenderá\n",
    "hasta alcanzar la inicial (hará una especie de pico) La elección de los valores inicial y pico se usa la siguiente\n",
    "técnica. Para el pico se utilizará la técnica explicada en el primer párrafo, para el inicial se elegirá uno que sea\n",
    "unas diez veces menor que el pico.\n",
    "\n",
    "### Regularización\n",
    "#### Introducción\n",
    "Tal y como vimos en los capítulos primeros se pueden usar la regularización L2 (keras.regularizers.l2) y L1\n",
    "(keras.regularizers.l1) para las NN o ambas a la vez (keras.regularizers.l1_l2). Hay que recordar que la penalización\n",
    "se utilizará solo en la fase de entrenamiento.\n",
    "\n",
    "layer = keras.layers.Dense(100, activation=\"elu, kernel_initializer=\"he_normal\",\n",
    "kernel_regularizer=keras.regularizers.l2(0.01))\n",
    "\n",
    "![](img/ut06_19.png)\n",
    "\n",
    "#### Dropout\n",
    "La idea es ignorar ciertas neuronas en este ciclo de aprendizaje. El porcentaje de neuronas es un hiperpámetro a\n",
    "ajustar, pero en NN suele estar entre 10% y 50%, más cerca del 20% en redes neuronales recurrentes y cerca del 40% o\n",
    "50% en las convolucionales\n",
    "\n",
    "Si observamos que el modelo se está sobreajustando podemos intentar incrementar el porcentaje de dropout, en caso de\n",
    "subajuste se tendrá que bajar o incluso eliminar si así fuera necesario.\n",
    "\n",
    "También es un factor el tamaño de la capa, en capas con muchas neuronas admiten mayor porcentaje de dropout que las\n",
    "capas con pocas neuronas\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "keras.layers.Flatten(input_shape=[28, 28]),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(300, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(100, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "keras.layers.Dropout(rate=0.2),\n",
    "keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "![](img/ut06_21.png)\n",
    "\n",
    "#### Regularización Max-Norm\n",
    "Para cada neurona constriñe el valor de los pesos dentro de un radio (r) de tal manera que, al reducir, incrementa\n",
    "la cantidad de regularización y mejorar el sobreajuste.\n",
    "\n",
    "keras.layers.Dense(100, activation=\"elu\",\n",
    "\t\tkernel_initializer=\"he_normal\",\n",
    "\t\tkernel_constraint=keras.constraints.max_norm(1.))\n",
    "\n",
    "#### Resumen\n",
    "Si se necesita un modelo disperso se tiene que utilizar la regularización L1.\n",
    "\n",
    "Si necesitamos un modelo de baja latencia (hace predicciones muy rápido) habrá que utilizar pocas capas y añadir\n",
    "Batch Normalization antes de cada capa y posiblemente usar una función de activación muy rápida como Leaky RELU o RELU.\n",
    "\n",
    "Si estamos haciendo un modelo de alto riesgo, Dropout mejorará el rendimiento.\n",
    "\n",
    "![](img/ut06_22.png)\n",
    "\n",
    "![](img/ut06_23.png)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}